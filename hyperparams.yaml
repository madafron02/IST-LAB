# Generated 2025-04-15 from:
# /scratch/mfron/IST-LAB/hparams/train_whisper_lora.yaml
# yamllint disable
# ################################
# Model: Whisper (Encoder-Decoder) + NLL + LoRA
# Augmentation: TimeDomainSpecAugment
# Authors: Peter Plantinga 2024, Adel Moumen 2022 & 2024, Titouan Parcollet 2022
# ################################

# Seed needs to be set at top of yaml, before objects with parameters are made
seed: 1986
__set_seed: !apply:speechbrain.utils.seed_everything [1986]
output_folder: results/whisper/1986
output_wer_folder: results/whisper/1986/
save_folder: results/whisper/1986/save
train_log: results/whisper/1986/train_log.txt

# URL for the whisper model
# Remove .nl if it doesn't work
whisper_hub: openai/whisper-medium
whisper_folder: results/whisper/1986/save/whisper_checkpoint


# Normalize the english inputs with
# the same normalization done in the paper
normalized_transcripts: true

# Data files
csv_folder: /scratch/mfron/IST-LAB/data
data_folder: /scratch/mfron/IST-LAB/JASMIN/kaldi_processed # e,g./path/to/LibriSpeech
train_splits: ['']
dev_splits: ['']
test_splits: [test_DT_read, test_DT_hmi, test_NnT_read, test_NnT_hmi]
skip_prep: true
train_csv: /scratch/mfron/IST-LAB/data/train.csv
valid_csv: /scratch/mfron/IST-LAB/data/val.csv
test_csv:
- /scratch/mfron/IST-LAB/data/test_DT_read.csv
- /scratch/mfron/IST-LAB/data/test_DT_hmi.csv
- /scratch/mfron/IST-LAB/data/test_NnT_read.csv
- /scratch/mfron/IST-LAB/data/test_NnT_hmi.csv

ckpt_interval_minutes: 1 # save checkpoint every N min

############################## Training Parameters #############################
freeze_encoder: true
number_of_epochs: 1
weight_decay: 0.01
lr_whisper: 1e-5
warmup_steps: 500
max_grad_norm: 2.0
sorting: ascending
precision: fp16 # bf16, fp16 or fp32
eval_precision: fp16
sampling_rate: 16_000

# With data_parallel batch_size is split into N jobs
# With DDP batch_size is multiplied by N jobs
# This setup works well with 1x 32GB GPU
batch_size: 2
test_batch_size: 2
grad_accumulation_factor: 8

# Decoding parameters
min_decode_ratio: 0.0
max_decode_ratio: 1.0
test_beam_size: 8

# Lora configuration
lora_rank: 16

####################### Model Parameters #######################################

train_loader_kwargs:
  batch_size: 2

valid_loader_kwargs:
  batch_size: 2

test_loader_kwargs:
  batch_size: 2


epoch_counter: &id004 !new:speechbrain.utils.epoch_loop.EpochCounter

  limit: 1

############################## Augmentations ###################################

# UNCOMMENT THIS SECTION TO ADD AUGMENTATIONS
# speed_perturb: !new:speechbrain.augment.time_domain.SpeedPerturb
#     orig_freq: !ref <sample_rate>
#     speeds: [95, 100, 105]

# # Frequency drop: randomly drops a number of frequency bands to zero.
# drop_freq: !new:speechbrain.augment.time_domain.DropFreq
#     drop_freq_low: 0  # Min frequency band dropout probability
#     drop_freq_high: 1  # Max frequency band dropout probability
#     drop_freq_count_low: 1  # Min number of frequency bands to drop
#     drop_freq_count_high: 3  # Max number of frequency bands to drop
#     drop_freq_width: 0.05  # Width of frequency bands to drop

# # Time drop: randomly drops a number of temporal chunks.
# drop_chunk: !new:speechbrain.augment.time_domain.DropChunk
#     drop_length_low: 1
#     drop_length_high: 5
#     drop_count_low: 1000
#     drop_count_high: 2000

# # Augmenter: Combines previously defined augmentations to perform data augmentation
# wav_augment: !new:speechbrain.augment.augmenter.Augmenter
#     concat_original: True
#     min_augmentations: 3
#     max_augmentations: 3
#     augment_prob: 1.0
#     augmentations: [
#         !ref <speed_perturb>,
#         !ref <drop_freq>,
#         !ref <drop_chunk>]

############################## Models ##########################################

whisper_pretrained: &id001 !new:speechbrain.lobes.models.huggingface_transformers.whisper.Whisper
  source: openai/whisper-medium
  freeze_encoder: true
  save_path: results/whisper/1986/save/whisper_checkpoint
  language: nl
  task: transcribe
  sampling_rate: 16_000

whisper: &id002 !new:speechbrain.nnet.adapters.AdaptedModel # TODO change to whisper when FT
  model_to_adapt: *id001
  adapter_class: !name:speechbrain.nnet.adapters.LoRA
  all_linear: true
  adapter_kwargs:
    rank: 16

log_softmax: !new:speechbrain.nnet.activations.Softmax
  apply_log: true

nll_loss: !name:speechbrain.nnet.losses.nll_loss

modules:
  whisper: *id002
whisper_opt_class: !name:torch.optim.AdamW
  lr: 1e-5
  weight_decay: 0.01

valid_search: !new:speechbrain.decoders.seq2seq.S2SWhisperGreedySearcher
  model: *id002
  min_decode_ratio: 0.0
  max_decode_ratio: 1.0

test_search: !new:speechbrain.decoders.seq2seq.S2SWhisperBeamSearcher
  module: [*id002]
  min_decode_ratio: 0.0
  max_decode_ratio: 1.0
  beam_size: 8

lr_annealing_whisper: &id003 !new:speechbrain.nnet.schedulers.NoamScheduler
  lr_initial: 1e-5
  n_warmup_steps: 500

############################## Logging and Pretrainer ##########################

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: results/whisper/1986/save
  recoverables:
    whisper: *id002
    scheduler_whisper: *id003
    counter: *id004
train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: results/whisper/1986/train_log.txt

error_rate_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats

cer_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats
  split_tokens: true

# pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
#     collect_in: !ref <save_folder>
#     loadables:
#         whisper: !ref <whisper_pretrained> #TODO we changed this from just <whisper>
#         whisper_opt: !ref <whisper_opt_class>
#         scheduler_whisper: !ref <lr_annealing_whisper>
#         counter: !ref <epoch_counter>
#     paths:
#         whisper: !ref <whisper_hub>/pytorch_model.bin 


    # paths:
    #     lm: !ref <pretrained_lm_tokenizer_path>/lm.ckpt
    #     tokenizer: !ref <pretrained_lm_tokenizer_path>/tokenizer.ckpt


    # pretrain = Pretrainer(loadables={'model': model}, paths={'model': 'speechbrain/spkrec-ecapa-voxceleb/embedding_model.ckpt'})
    # # We download the pretrained model from HuggingFace in this case
    # pretrain.collect_files()
    # pretrain.load_collected()
